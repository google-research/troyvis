# baseline_new: w3, efficient early fusion, efficient level 3
_BASE_: "base_clip_teacher_image_R50.yaml"
FIND_UNUSED_PARAMETERS: False
MODEL:
  WEIGHTS: "exp/Final_Stage1_baseline_new_enc3_dec3_evaclipl_64g/model_final.pth"
  VISUAL_PROMPT: False
  EARLYFUSION: True
  EFFI_EARLY_FUSION: True
  EFFI_LVL: 3
  SEM_SEG_HEAD:
    TRANSFORMER_ENC_LAYERS: 3
  MaskDINO:
    DEC_LAYERS: 3
  LANGUAGE_BACKBONE:
    LANG_DIM: 768
  TEXT:
    ARCH: EVA02_L_CLIP_teacher
DATASETS:
  TRAIN: ("openimage_train", "objects365_v2_train", "lvis_v1_train", "vg_train", "vg_captiontrain", "coco_2017_train", "image_yt19", "image_yt21", "image_o",)
  TEST: ("coco_2017_val", "lvis_v1_minival",)  
SOLVER:  
  IMS_PER_BATCH: 128
  BASE_LR: 0.0001
  STEPS: (210000, 270000) # [70%, 90%]
  MAX_ITER: 300000
  CHECKPOINT_PERIOD: 10000
  TEXTENCODER_MULTIPLIER: 0.1
TEST:
  EVAL_PERIOD: 0
DATALOADER:
  SAMPLER_TRAIN: "MultiDatasetSampler"
  DATASET_RATIO: [1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 0.3, 0.3, 0.3]
  USE_DIFF_BS_SIZE: True
  DATASET_BS: [2, 2, 2, 2, 2, 2, 2, 2, 2]
  USE_RFS: [True, True, True, False, False, False, False, False, False]
  DATASET_ANN: ['box', 'box', 'box', 'box', 'box', 'box', 'box', 'box', 'box']
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 2
OUTPUT_DIR: ./exp/Final_Stage2_baseline_new_enc3_dec3_evaclipl_64g